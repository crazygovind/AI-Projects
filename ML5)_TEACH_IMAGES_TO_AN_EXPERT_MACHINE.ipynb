{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPX2ft9QWbItdxcx+5wPs3p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crazygovind/Image-Processing-Machine-Learning/blob/master/ML5)_TEACH_IMAGES_TO_AN_EXPERT_MACHINE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Objectives\n",
        "Build a neural network using Tensorflow and Keras\n",
        "\n",
        "Train the neural network to see the difference between different types of fashion items\n",
        "\n",
        "Test the accuracy of your neural network on test images.\n",
        "\n",
        "#Database\n",
        "We will be trying a Tensorflow example problem here. The example we are considering is the one on the Fashion MNIST database. This database contains 70,000 images of articles of clothing. The classes available are ‘T-shirt/top‘, ‘Trouser‘, ‘Pullover‘, ‘Dress‘, ‘Coat’, ‘Sandal‘, ‘Shirt‘, ‘Sneaker‘, ‘Bag‘, ‘Ankle boot‘.\n",
        "\n",
        "This database can be downloaded directly using a keras command. So we can begin directly.\n",
        "\n",
        "We will be splitting the database into 60,000 training images and 10,000 test images."
      ],
      "metadata": {
        "id": "EY4uieDelAlV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCfsh7gXcYGn",
        "outputId": "87c239dd-4857-49a3-ad74-35074920c319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[STATUS] TRAINING\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4964 - accuracy: 0.8247\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3719 - accuracy: 0.8660\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3341 - accuracy: 0.8785\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3092 - accuracy: 0.8863\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2928 - accuracy: 0.8919\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2787 - accuracy: 0.8971\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2666 - accuracy: 0.9000\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2558 - accuracy: 0.9052\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2446 - accuracy: 0.9096\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2368 - accuracy: 0.9118\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2285 - accuracy: 0.9140\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2211 - accuracy: 0.9170\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2132 - accuracy: 0.9205\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2078 - accuracy: 0.9229\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2017 - accuracy: 0.9241\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1975 - accuracy: 0.9261\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1891 - accuracy: 0.9297\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1841 - accuracy: 0.9312\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1794 - accuracy: 0.9325\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1750 - accuracy: 0.9343\n",
            "\n",
            "\n",
            "[STATUS] TESTING\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8855\n",
            "Test accuracy: 0.8855000138282776\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = keras.Sequential([\n",
        "keras.layers.Flatten(input_shape=(28, 28)),\n",
        "keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "optimizer=tf.optimizers.Adam()\n",
        "model.compile(optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "print(\"\\n\\n[STATUS] TRAINING\")\n",
        "model.fit(train_images, train_labels, epochs=20)\n",
        "print(\"\\n\\n[STATUS] TESTING\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)"
      ]
    }
  ]
}